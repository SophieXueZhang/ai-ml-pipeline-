#!/usr/bin/env python3
"""
DiT (Document Image Transformer) è®­ç»ƒè„šæœ¬
ç”¨äºåŒ»ä¿æ–‡æ¡£åˆ†ç±»ä»»åŠ¡
"""

import os
import sys
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from transformers import (
    AutoModel, AutoImageProcessor, AutoConfig,
    AdamW, get_scheduler
)
import pandas as pd
import numpy as np
from pathlib import Path
from PIL import Image
import json
import logging
from tqdm import tqdm
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class HealthcareDocumentDataset(Dataset):
    """åŒ»ä¿æ–‡æ¡£æ•°æ®é›†"""
    
    def __init__(self, csv_path, images_dir, processor, transform=None):
        self.df = pd.read_csv(csv_path)
        self.images_dir = Path(images_dir)
        self.processor = processor
        self.transform = transform
        
    def __len__(self):
        return len(self.df)
    
    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        
        # åŠ è½½å›¾ç‰‡
        if 'new_image_path' in row and pd.notna(row['new_image_path']):
            image_path = self.images_dir.parent / "images" / row['new_image_path']
        else:
            image_path = self.images_dir / row['image_path']
            
        try:
            image = Image.open(image_path).convert('RGB')
        except Exception as e:
            logger.warning(f"æ— æ³•åŠ è½½å›¾ç‰‡ {image_path}: {e}")
            # åˆ›å»ºä¸€ä¸ªç©ºç™½å›¾ç‰‡ä½œä¸ºæ›¿ä»£
            image = Image.new('RGB', (224, 224), color='white')
        
        # é¢„å¤„ç†å›¾ç‰‡
        if self.processor:
            inputs = self.processor(image, return_tensors="pt")
            pixel_values = inputs['pixel_values'].squeeze(0)  # ç§»é™¤batchç»´åº¦
        else:
            # å¦‚æœæ²¡æœ‰processorï¼Œä½¿ç”¨åŸºæœ¬çš„è½¬æ¢
            import torchvision.transforms as transforms
            transform = transforms.Compose([
                transforms.Resize((224, 224)),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                                   std=[0.229, 0.224, 0.225])
            ])
            pixel_values = transform(image)
        
        # è·å–æ ‡ç­¾
        label = int(row['label'])
        
        return {
            'pixel_values': pixel_values,
            'labels': torch.tensor(label, dtype=torch.long)
        }

class DiTClassifier(nn.Module):
    """åŸºäºDiTçš„æ–‡æ¡£åˆ†ç±»å™¨"""
    
    def __init__(self, model_name_or_path, num_classes=5):
        super().__init__()
        
        # åŠ è½½DiTæ¨¡å‹
        self.config = AutoConfig.from_pretrained(model_name_or_path)
        self.dit = AutoModel.from_pretrained(model_name_or_path)
        
        # åˆ†ç±»å¤´
        hidden_size = self.config.hidden_size
        self.classifier = nn.Sequential(
            nn.Dropout(0.1),
            nn.Linear(hidden_size, hidden_size // 2),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_size // 2, num_classes)
        )
        
    def forward(self, pixel_values, labels=None):
        # DiTå‰å‘ä¼ æ’­
        outputs = self.dit(pixel_values=pixel_values)
        
        # ä½¿ç”¨[CLS] tokenæˆ–æ± åŒ–åçš„è¡¨ç¤º
        if hasattr(outputs, 'pooler_output') and outputs.pooler_output is not None:
            pooled_output = outputs.pooler_output
        else:
            # ä½¿ç”¨æœ€åä¸€å±‚çš„å¹³å‡æ± åŒ–
            last_hidden_state = outputs.last_hidden_state
            pooled_output = last_hidden_state.mean(dim=1)
        
        # åˆ†ç±»
        logits = self.classifier(pooled_output)
        
        loss = None
        if labels is not None:
            loss_fct = nn.CrossEntropyLoss()
            loss = loss_fct(logits.view(-1, self.classifier[-1].out_features), labels.view(-1))
        
        return {
            'loss': loss,
            'logits': logits,
            'hidden_states': outputs.last_hidden_state if hasattr(outputs, 'last_hidden_state') else None
        }

class DiTTrainer:
    """DiTè®­ç»ƒå™¨"""
    
    def __init__(self, config):
        self.config = config
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        logger.info(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.output_dir = Path(config['output_dir'])
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # åŠ è½½å¤„ç†å™¨
        self.processor = AutoImageProcessor.from_pretrained(config['model_name'])
        
        # åŠ è½½ç±»åˆ«ä¿¡æ¯
        with open(config['class_info_path'], 'r', encoding='utf-8') as f:
            self.class_info = json.load(f)
        self.num_classes = len(self.class_info['target_classes'])
        
    def create_data_loaders(self):
        """åˆ›å»ºæ•°æ®åŠ è½½å™¨"""
        logger.info("åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
        
        # è®­ç»ƒé›†
        train_dataset = HealthcareDocumentDataset(
            csv_path=self.config['train_csv'],
            images_dir=self.config['images_dir'],
            processor=self.processor
        )
        
        # éªŒè¯é›†
        val_dataset = HealthcareDocumentDataset(
            csv_path=self.config['val_csv'], 
            images_dir=self.config['images_dir'],
            processor=self.processor
        )
        
        # æ•°æ®åŠ è½½å™¨
        train_loader = DataLoader(
            train_dataset,
            batch_size=self.config['batch_size'],
            shuffle=True,
            num_workers=2,
            pin_memory=True
        )
        
        val_loader = DataLoader(
            val_dataset,
            batch_size=self.config['batch_size'],
            shuffle=False,
            num_workers=2,
            pin_memory=True
        )
        
        logger.info(f"è®­ç»ƒé›†å¤§å°: {len(train_dataset)}")
        logger.info(f"éªŒè¯é›†å¤§å°: {len(val_dataset)}")
        
        return train_loader, val_loader
    
    def create_model(self):
        """åˆ›å»ºæ¨¡å‹"""
        logger.info("åˆ›å»ºDiTåˆ†ç±»æ¨¡å‹...")
        
        model = DiTClassifier(
            model_name_or_path=self.config['model_name'],
            num_classes=self.num_classes
        )
        model.to(self.device)
        
        return model
    
    def create_optimizer_and_scheduler(self, model, num_training_steps):
        """åˆ›å»ºä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨"""
        # ä¼˜åŒ–å™¨
        optimizer = AdamW(
            model.parameters(),
            lr=self.config['learning_rate'],
            weight_decay=self.config['weight_decay']
        )
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        scheduler = get_scheduler(
            name="linear",
            optimizer=optimizer,
            num_warmup_steps=self.config['warmup_steps'],
            num_training_steps=num_training_steps
        )
        
        return optimizer, scheduler
    
    def train_epoch(self, model, train_loader, optimizer, scheduler):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        model.train()
        total_loss = 0
        correct_predictions = 0
        total_predictions = 0
        
        progress_bar = tqdm(train_loader, desc="è®­ç»ƒ")
        
        for batch in progress_bar:
            # ç§»åŠ¨åˆ°è®¾å¤‡
            pixel_values = batch['pixel_values'].to(self.device)
            labels = batch['labels'].to(self.device)
            
            # å‰å‘ä¼ æ’­
            outputs = model(pixel_values=pixel_values, labels=labels)
            loss = outputs['loss']
            
            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            scheduler.step()
            
            # ç»Ÿè®¡
            total_loss += loss.item()
            predictions = torch.argmax(outputs['logits'], dim=-1)
            correct_predictions += (predictions == labels).sum().item()
            total_predictions += labels.size(0)
            
            # æ›´æ–°è¿›åº¦æ¡
            progress_bar.set_postfix({
                'loss': f'{loss.item():.4f}',
                'acc': f'{correct_predictions/total_predictions:.4f}'
            })
        
        avg_loss = total_loss / len(train_loader)
        accuracy = correct_predictions / total_predictions
        
        return avg_loss, accuracy
    
    def evaluate(self, model, val_loader):
        """è¯„ä¼°æ¨¡å‹"""
        model.eval()
        total_loss = 0
        all_predictions = []
        all_labels = []
        
        with torch.no_grad():
            for batch in tqdm(val_loader, desc="éªŒè¯"):
                pixel_values = batch['pixel_values'].to(self.device)
                labels = batch['labels'].to(self.device)
                
                outputs = model(pixel_values=pixel_values, labels=labels)
                loss = outputs['loss']
                
                total_loss += loss.item()
                predictions = torch.argmax(outputs['logits'], dim=-1)
                
                all_predictions.extend(predictions.cpu().numpy())
                all_labels.extend(labels.cpu().numpy())
        
        avg_loss = total_loss / len(val_loader)
        accuracy = accuracy_score(all_labels, all_predictions)
        
        return avg_loss, accuracy, all_predictions, all_labels
    
    def save_model(self, model, epoch, accuracy):
        """ä¿å­˜æ¨¡å‹"""
        model_path = self.output_dir / f"dit_classifier_epoch_{epoch}_acc_{accuracy:.4f}"
        model_path.mkdir(exist_ok=True)
        
        # ä¿å­˜æ¨¡å‹
        model.dit.save_pretrained(model_path / "dit")
        self.processor.save_pretrained(model_path / "processor")
        
        # ä¿å­˜åˆ†ç±»å¤´
        torch.save(model.classifier.state_dict(), model_path / "classifier.pth")
        
        # ä¿å­˜é…ç½®
        config_to_save = {
            'num_classes': self.num_classes,
            'class_info': self.class_info,
            'model_name': self.config['model_name'],
            'epoch': epoch,
            'accuracy': accuracy
        }
        
        with open(model_path / "training_config.json", 'w', encoding='utf-8') as f:
            json.dump(config_to_save, f, indent=2, ensure_ascii=False)
        
        logger.info(f"æ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")
        return model_path
    
    def plot_confusion_matrix(self, y_true, y_pred, epoch):
        """ç»˜åˆ¶æ··æ·†çŸ©é˜µ"""
        class_names = list(self.class_info['target_classes'].keys())
        cm = confusion_matrix(y_true, y_pred)
        
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                   xticklabels=class_names, yticklabels=class_names)
        plt.title(f'Confusion Matrix - Epoch {epoch}')
        plt.ylabel('True Label')
        plt.xlabel('Predicted Label')
        
        # ä¿å­˜å›¾ç‰‡
        plt.savefig(self.output_dir / f'confusion_matrix_epoch_{epoch}.png', 
                   dpi=300, bbox_inches='tight')
        plt.close()
    
    def train(self):
        """ä¸»è®­ç»ƒæµç¨‹"""
        logger.info("å¼€å§‹è®­ç»ƒDiTåˆ†ç±»å™¨...")
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_loader, val_loader = self.create_data_loaders()
        
        # åˆ›å»ºæ¨¡å‹
        model = self.create_model()
        
        # è®¡ç®—è®­ç»ƒæ­¥æ•°
        num_training_steps = len(train_loader) * self.config['epochs']
        
        # åˆ›å»ºä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
        optimizer, scheduler = self.create_optimizer_and_scheduler(model, num_training_steps)
        
        # è®­ç»ƒå¾ªç¯
        best_accuracy = 0
        best_model_path = None
        
        for epoch in range(self.config['epochs']):
            logger.info(f"Epoch {epoch + 1}/{self.config['epochs']}")
            
            # è®­ç»ƒ
            train_loss, train_acc = self.train_epoch(model, train_loader, optimizer, scheduler)
            
            # éªŒè¯
            val_loss, val_acc, val_predictions, val_labels = self.evaluate(model, val_loader)
            
            logger.info(f"è®­ç»ƒæŸå¤±: {train_loss:.4f}, è®­ç»ƒå‡†ç¡®ç‡: {train_acc:.4f}")
            logger.info(f"éªŒè¯æŸå¤±: {val_loss:.4f}, éªŒè¯å‡†ç¡®ç‡: {val_acc:.4f}")
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_acc > best_accuracy:
                best_accuracy = val_acc
                best_model_path = self.save_model(model, epoch + 1, val_acc)
            
            # ç»˜åˆ¶æ··æ·†çŸ©é˜µ
            self.plot_confusion_matrix(val_labels, val_predictions, epoch + 1)
            
            # æ‰“å°åˆ†ç±»æŠ¥å‘Š
            class_names = list(self.class_info['target_classes'].keys())
            report = classification_report(val_labels, val_predictions, 
                                         target_names=class_names, digits=4)
            logger.info(f"\nåˆ†ç±»æŠ¥å‘Š:\n{report}")
        
        logger.info(f"ğŸ‰ è®­ç»ƒå®Œæˆï¼æœ€ä½³å‡†ç¡®ç‡: {best_accuracy:.4f}")
        logger.info(f"æœ€ä½³æ¨¡å‹ä¿å­˜åœ¨: {best_model_path}")
        
        return best_model_path, best_accuracy

def main():
    """ä¸»å‡½æ•°"""
    # é…ç½®
    base_dir = Path(__file__).parent.parent
    data_dir = base_dir / "data" / "rvl_cdip" / "processed"
    
    config = {
        'model_name': str(base_dir / "models" / "dit_base"),
        'train_csv': str(data_dir / "train.csv"),
        'val_csv': str(data_dir / "val.csv"),
        'images_dir': str(data_dir),
        'class_info_path': str(data_dir / "class_info.json"),
        'output_dir': str(base_dir / "models" / "classification"),
        'batch_size': 16,
        'learning_rate': 2e-5,
        'weight_decay': 0.01,
        'epochs': 3,
        'warmup_steps': 500
    }
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    required_files = [
        config['train_csv'],
        config['val_csv'],
        config['class_info_path']
    ]
    
    for file_path in required_files:
        if not Path(file_path).exists():
            logger.error(f"å¿…éœ€æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            logger.error("è¯·å…ˆè¿è¡Œæ•°æ®é¢„å¤„ç†è„šæœ¬")
            return False
    
    # å¦‚æœæœ¬åœ°DiTæ¨¡å‹ä¸å­˜åœ¨ï¼Œä½¿ç”¨åœ¨çº¿ç‰ˆæœ¬
    if not Path(config['model_name']).exists():
        logger.warning("æœ¬åœ°DiTæ¨¡å‹ä¸å­˜åœ¨ï¼Œä½¿ç”¨åœ¨çº¿ç‰ˆæœ¬")
        config['model_name'] = "microsoft/dit-base-finetuned-rvlcdip"
    
    # åˆ›å»ºè®­ç»ƒå™¨å¹¶è®­ç»ƒ
    trainer = DiTTrainer(config)
    best_model_path, best_accuracy = trainer.train()
    
    logger.info("è®­ç»ƒæˆåŠŸå®Œæˆï¼")
    return True

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 