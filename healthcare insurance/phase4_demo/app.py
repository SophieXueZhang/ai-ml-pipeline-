#!/usr/bin/env python3
"""
åŒ»ç–—ä¿é™©æ–‡æ¡£å¤„ç†FastAPIåº”ç”¨
ç«¯åˆ°ç«¯å¤„ç†ï¼šä¸Šä¼ æ–‡æ¡£ -> åˆ†ç±» -> ä¿¡æ¯æŠ½å– -> å­—æ®µéªŒè¯ -> è¿”å›ç»“æ„åŒ–JSON
"""

import os
import sys
import json
import logging
from pathlib import Path
from typing import List, Dict, Optional, Union
import time
import uuid
from datetime import datetime

import torch
from PIL import Image
import pandas as pd
import numpy as np

from fastapi import FastAPI, File, UploadFile, HTTPException, BackgroundTasks
from fastapi.responses import JSONResponse, HTMLResponse
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
sys.path.append(str(Path(__file__).parent.parent))

from phase2_classification.train_dit import DiTClassifier
from phase3_extraction.train_layoutlm import MedicalFieldExtractor
from phase4_demo.validation_utils import MedicalFieldValidator

# Transformers imports
from transformers import (
    AutoImageProcessor, LayoutLMv3Processor,
    LayoutLMv3ForTokenClassification, AutoConfig
)

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# FastAPIåº”ç”¨
app = FastAPI(
    title="åŒ»ç–—ä¿é™©æ–‡æ¡£æ™ºèƒ½å¤„ç†ç³»ç»Ÿ",
    description="è‡ªåŠ¨åˆ†ç±»åŒ»ä¿æ–‡æ¡£å¹¶æŠ½å–å…³é”®ä¿¡æ¯",
    version="1.0.0"
)

# CORSè®¾ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# æ•°æ®æ¨¡å‹
class ProcessingResult(BaseModel):
    """å¤„ç†ç»“æœæ¨¡å‹"""
    request_id: str
    status: str
    processing_time: float
    document_type: Optional[str] = None
    confidence: Optional[float] = None
    extracted_fields: Optional[Dict] = None
    validation_results: Optional[Dict] = None
    recommendations: Optional[List[str]] = None
    error_message: Optional[str] = None

class HealthStatus(BaseModel):
    """å¥åº·æ£€æŸ¥æ¨¡å‹"""
    status: str
    timestamp: str
    models_loaded: Dict[str, bool]
    version: str

# å…¨å±€å˜é‡
classification_model = None
classification_processor = None
extraction_model = None
extraction_processor = None
field_extractor = None
validator = None

# é…ç½®
CONFIG = {
    'max_file_size': 10 * 1024 * 1024,  # 10MB
    'allowed_extensions': ['.pdf', '.jpg', '.jpeg', '.png', '.tiff'],
    'upload_dir': Path(__file__).parent / 'uploads',
    'output_dir': Path(__file__).parent / 'outputs'
}

def load_models():
    """åŠ è½½é¢„è®­ç»ƒæ¨¡å‹"""
    global classification_model, classification_processor
    global extraction_model, extraction_processor
    global field_extractor, validator
    
    logger.info("å¼€å§‹åŠ è½½æ¨¡å‹...")
    
    try:
        # éªŒè¯å™¨
        validator = MedicalFieldValidator()
        logger.info("âœ“ éªŒè¯å™¨åŠ è½½å®Œæˆ")
        
        # è·å–åŸºç¡€ç›®å½•
        base_dir = Path(__file__).parent.parent
        
        # æŸ¥æ‰¾æœ€ä½³åˆ†ç±»æ¨¡å‹
        classification_dir = base_dir / "models" / "classification"
        if classification_dir.exists():
            model_dirs = [d for d in classification_dir.iterdir() if d.is_dir() and 'dit_classifier' in d.name]
            if model_dirs:
                # é€‰æ‹©å‡†ç¡®ç‡æœ€é«˜çš„æ¨¡å‹
                best_model_dir = max(model_dirs, key=lambda x: float(x.name.split('_acc_')[-1]) if '_acc_' in x.name else 0)
                
                logger.info(f"åŠ è½½åˆ†ç±»æ¨¡å‹: {best_model_dir}")
                
                # åŠ è½½åˆ†ç±»æ¨¡å‹é…ç½®
                with open(best_model_dir / "training_config.json", 'r') as f:
                    config = json.load(f)
                
                # åŠ è½½å¤„ç†å™¨
                classification_processor = AutoImageProcessor.from_pretrained(best_model_dir / "dit")
                
                # åŠ è½½æ¨¡å‹
                classification_model = DiTClassifier(
                    model_name_or_path=str(best_model_dir / "dit"),
                    num_classes=config['num_classes']
                )
                
                # åŠ è½½åˆ†ç±»å¤´æƒé‡
                classifier_path = best_model_dir / "classifier.pth"
                if classifier_path.exists():
                    classification_model.classifier.load_state_dict(torch.load(classifier_path, map_location='cpu'))
                
                classification_model.eval()
                logger.info("âœ“ åˆ†ç±»æ¨¡å‹åŠ è½½å®Œæˆ")
            else:
                logger.warning("æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„åˆ†ç±»æ¨¡å‹ï¼Œä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹")
                classification_processor = AutoImageProcessor.from_pretrained("microsoft/dit-base-finetuned-rvlcdip")
        
        # æŸ¥æ‰¾æœ€ä½³æŠ½å–æ¨¡å‹
        extraction_dir = base_dir / "models" / "extraction"  
        if extraction_dir.exists():
            model_dirs = [d for d in extraction_dir.iterdir() if d.is_dir() and 'layoutlmv3' in d.name]
            if model_dirs:
                # é€‰æ‹©F1åˆ†æ•°æœ€é«˜çš„æ¨¡å‹
                best_model_dir = max(model_dirs, key=lambda x: float(x.name.split('_f1_')[-1]) if '_f1_' in x.name else 0)
                
                logger.info(f"åŠ è½½æŠ½å–æ¨¡å‹: {best_model_dir}")
                
                # åŠ è½½æŠ½å–æ¨¡å‹é…ç½®
                with open(best_model_dir / "training_config.json", 'r') as f:
                    config = json.load(f)
                
                # åŠ è½½å¤„ç†å™¨å’Œæ¨¡å‹
                extraction_processor = LayoutLMv3Processor.from_pretrained(best_model_dir)
                extraction_model = LayoutLMv3ForTokenClassification.from_pretrained(best_model_dir)
                extraction_model.eval()
                
                # åˆ›å»ºå­—æ®µæŠ½å–å™¨
                field_extractor = MedicalFieldExtractor(
                    config['label_info']['label_map'],
                    config['label_info']['medical_fields']
                )
                
                logger.info("âœ“ æŠ½å–æ¨¡å‹åŠ è½½å®Œæˆ")
            else:
                logger.warning("æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æŠ½å–æ¨¡å‹")
        
        logger.info("ğŸ‰ æ‰€æœ‰æ¨¡å‹åŠ è½½å®Œæˆ")
        
    except Exception as e:
        logger.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        raise

def classify_document(image: Image.Image) -> Dict[str, any]:
    """åˆ†ç±»æ–‡æ¡£"""
    if classification_model is None or classification_processor is None:
        return {"document_type": "unknown", "confidence": 0.0, "error": "åˆ†ç±»æ¨¡å‹æœªåŠ è½½"}
    
    try:
        # é¢„å¤„ç†å›¾ç‰‡
        inputs = classification_processor(image, return_tensors="pt")
        
        # æ¨ç†
        with torch.no_grad():
            outputs = classification_model(pixel_values=inputs['pixel_values'])
            probabilities = torch.softmax(outputs['logits'], dim=-1)
            predicted_class = torch.argmax(probabilities, dim=-1).item()
            confidence = probabilities[0][predicted_class].item()
        
        # ç±»åˆ«æ˜ å°„
        class_names = ['invoice', 'letter', 'email', 'memo', 'form']
        document_type = class_names[predicted_class] if predicted_class < len(class_names) else 'unknown'
        
        return {
            "document_type": document_type,
            "confidence": confidence,
            "all_scores": {class_names[i]: probabilities[0][i].item() for i in range(len(class_names))}
        }
        
    except Exception as e:
        logger.error(f"æ–‡æ¡£åˆ†ç±»å¤±è´¥: {e}")
        return {"document_type": "unknown", "confidence": 0.0, "error": str(e)}

def extract_information(image: Image.Image) -> Dict[str, any]:
    """æŠ½å–ä¿¡æ¯"""
    if extraction_model is None or extraction_processor is None or field_extractor is None:
        return {"extracted_fields": {}, "error": "æŠ½å–æ¨¡å‹æœªåŠ è½½"}
    
    try:
        # ç®€å•OCRï¼ˆè¿™é‡Œå¯ä»¥é›†æˆæ›´å¥½çš„OCRï¼‰
        # ä¸ºæ¼”ç¤ºç›®çš„ï¼Œåˆ›å»ºæ¨¡æ‹Ÿçš„OCRç»“æœ
        words = ["Provider:", "Dr.", "John", "Smith", "Phone:", "555-123-4567", "Patient:", "Jane", "Doe", "Amount:", "$250.00"]
        boxes = [[50, 50, 120, 80], [130, 50, 160, 80], [170, 50, 220, 80], [230, 50, 290, 80],
                [50, 100, 110, 130], [120, 100, 250, 130], [50, 150, 120, 180], [130, 150, 180, 180], 
                [190, 150, 240, 180], [50, 200, 110, 230], [120, 200, 200, 230]]
        
        # é¢„å¤„ç†
        encoding = extraction_processor(
            image,
            words,
            boxes=boxes,
            truncation=True,
            padding='max_length',
            max_length=512,
            return_tensors='pt'
        )
        
        # é¢„æµ‹
        with torch.no_grad():
            outputs = extraction_model(**encoding)
            predictions = torch.argmax(outputs.logits, dim=-1)
            
            # è·å–æœ‰æ•ˆé¢„æµ‹
            active_mask = encoding['attention_mask'][0].cpu().numpy() == 1
            active_predictions = predictions[0][active_mask].cpu().numpy()
            
            # æŠ½å–å®ä½“
            entities = field_extractor.extract_entities(
                words, boxes, active_predictions[:len(words)]
            )
            
            # æ˜ å°„åˆ°åŒ»ç–—å­—æ®µ
            medical_fields = field_extractor.map_to_medical_fields(entities)
            
            return {
                "extracted_fields": medical_fields,
                "entities": entities,
                "raw_predictions": active_predictions[:len(words)].tolist()
            }
            
    except Exception as e:
        logger.error(f"ä¿¡æ¯æŠ½å–å¤±è´¥: {e}")
        return {"extracted_fields": {}, "error": str(e)}

@app.on_event("startup")
async def startup_event():
    """å¯åŠ¨æ—¶åŠ è½½æ¨¡å‹"""
    # åˆ›å»ºå¿…è¦çš„ç›®å½•
    CONFIG['upload_dir'].mkdir(exist_ok=True)
    CONFIG['output_dir'].mkdir(exist_ok=True)
    
    # åŠ è½½æ¨¡å‹
    try:
        load_models()
    except Exception as e:
        logger.error(f"å¯åŠ¨æ—¶æ¨¡å‹åŠ è½½å¤±è´¥: {e}")

@app.get("/", response_class=HTMLResponse)
async def root():
    """ä¸»é¡µ"""
    html_content = """
    <!DOCTYPE html>
    <html>
    <head>
        <title>åŒ»ç–—ä¿é™©æ–‡æ¡£å¤„ç†ç³»ç»Ÿ</title>
        <meta charset="utf-8">
        <style>
            body { font-family: Arial, sans-serif; max-width: 800px; margin: 50px auto; padding: 20px; }
            .header { text-align: center; color: #2c3e50; }
            .upload-area { border: 2px dashed #3498db; padding: 30px; text-align: center; margin: 20px 0; }
            .upload-area:hover { background-color: #ecf0f1; }
            button { background-color: #3498db; color: white; border: none; padding: 10px 20px; cursor: pointer; border-radius: 5px; }
            button:hover { background-color: #2980b9; }
            .result { margin-top: 20px; padding: 15px; background-color: #f8f9fa; border-radius: 5px; }
            .error { color: #e74c3c; }
            .success { color: #27ae60; }
        </style>
    </head>
    <body>
        <div class="header">
            <h1>ğŸ¥ åŒ»ç–—ä¿é™©æ–‡æ¡£æ™ºèƒ½å¤„ç†ç³»ç»Ÿ</h1>
            <p>ä¸Šä¼ åŒ»ä¿æ–‡æ¡£ï¼Œè‡ªåŠ¨è¯†åˆ«ç±»å‹å¹¶æŠ½å–å…³é”®ä¿¡æ¯</p>
        </div>
        
        <div class="upload-area">
            <p>ğŸ“„ ç‚¹å‡»é€‰æ‹©æ–‡ä»¶æˆ–æ‹–æ‹½æ–‡ä»¶åˆ°æ­¤å¤„</p>
            <input type="file" id="fileInput" accept=".pdf,.jpg,.jpeg,.png,.tiff" style="display: none;">
            <button onclick="document.getElementById('fileInput').click()">é€‰æ‹©æ–‡ä»¶</button>
        </div>
        
        <div id="result" class="result" style="display: none;"></div>
        
        <div style="margin-top: 30px;">
            <h3>ğŸ”§ APIæ¥å£</h3>
            <ul>
                <li><strong>POST /process</strong> - å¤„ç†æ–‡æ¡£</li>
                <li><strong>GET /health</strong> - å¥åº·æ£€æŸ¥</li>
                <li><strong>GET /docs</strong> - æ¥å£æ–‡æ¡£</li>
            </ul>
        </div>
        
        <script>
            document.getElementById('fileInput').onchange = function(e) {
                const file = e.target.files[0];
                if (!file) return;
                
                const formData = new FormData();
                formData.append('file', file);
                
                const resultDiv = document.getElementById('result');
                resultDiv.style.display = 'block';
                resultDiv.innerHTML = '<p>â³ å¤„ç†ä¸­ï¼Œè¯·ç¨å€™...</p>';
                
                fetch('/process', {
                    method: 'POST',
                    body: formData
                })
                .then(response => response.json())
                .then(data => {
                    if (data.status === 'success') {
                        resultDiv.innerHTML = `
                            <h4 class="success">âœ… å¤„ç†æˆåŠŸ</h4>
                            <p><strong>æ–‡æ¡£ç±»å‹:</strong> ${data.document_type} (ç½®ä¿¡åº¦: ${(data.confidence * 100).toFixed(1)}%)</p>
                            <p><strong>å¤„ç†æ—¶é—´:</strong> ${data.processing_time.toFixed(2)}ç§’</p>
                            <h5>æŠ½å–çš„ä¿¡æ¯:</h5>
                            <pre>${JSON.stringify(data.extracted_fields || {}, null, 2)}</pre>
                            <h5>éªŒè¯ç»“æœ:</h5>
                            <pre>${JSON.stringify(data.validation_results || {}, null, 2)}</pre>
                        `;
                    } else {
                        resultDiv.innerHTML = `
                            <h4 class="error">âŒ å¤„ç†å¤±è´¥</h4>
                            <p>${data.error_message}</p>
                        `;
                    }
                })
                .catch(error => {
                    resultDiv.innerHTML = `
                        <h4 class="error">âŒ ç½‘ç»œé”™è¯¯</h4>
                        <p>${error.message}</p>
                    `;
                });
            };
        </script>
    </body>
    </html>
    """
    return html_content

@app.get("/health", response_model=HealthStatus)
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    models_status = {
        "classification_model": classification_model is not None,
        "extraction_model": extraction_model is not None,
        "validator": validator is not None
    }
    
    overall_status = "healthy" if all(models_status.values()) else "unhealthy"
    
    return HealthStatus(
        status=overall_status,
        timestamp=datetime.now().isoformat(),
        models_loaded=models_status,
        version="1.0.0"
    )

@app.post("/process", response_model=ProcessingResult)
async def process_document(file: UploadFile = File(...)):
    """å¤„ç†æ–‡æ¡£"""
    start_time = time.time()
    request_id = str(uuid.uuid4())
    
    try:
        # éªŒè¯æ–‡ä»¶
        if file.size > CONFIG['max_file_size']:
            raise HTTPException(status_code=413, detail="æ–‡ä»¶å¤ªå¤§")
        
        file_ext = Path(file.filename).suffix.lower()
        if file_ext not in CONFIG['allowed_extensions']:
            raise HTTPException(status_code=400, detail="ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼")
        
        # è¯»å–å¹¶å¤„ç†å›¾ç‰‡
        contents = await file.read()
        
        try:
            image = Image.open(io.BytesIO(contents)).convert('RGB')
        except Exception as e:
            raise HTTPException(status_code=400, detail=f"æ— æ³•è¯»å–å›¾ç‰‡: {e}")
        
        # æ­¥éª¤1: åˆ†ç±»æ–‡æ¡£
        classification_result = classify_document(image)
        
        # æ­¥éª¤2: æŠ½å–ä¿¡æ¯ï¼ˆå¦‚æœæ˜¯è¡¨å•ç±»å‹ï¼‰
        extracted_fields = {}
        if classification_result.get('document_type') in ['form', 'invoice']:
            extraction_result = extract_information(image)
            extracted_fields = extraction_result.get('extracted_fields', {})
        
        # æ­¥éª¤3: éªŒè¯å­—æ®µ
        validation_results = {}
        validation_summary = {}
        if extracted_fields and validator:
            validation_results = validator.validate_all_fields(extracted_fields)
            validation_summary = validator.generate_validation_summary(validation_results)
        
        # è®¡ç®—å¤„ç†æ—¶é—´
        processing_time = time.time() - start_time
        
        # æ„å»ºç»“æœ
        result = ProcessingResult(
            request_id=request_id,
            status="success",
            processing_time=processing_time,
            document_type=classification_result.get('document_type'),
            confidence=classification_result.get('confidence'),
            extracted_fields=extracted_fields,
            validation_results={
                'field_results': validation_results,
                'summary': validation_summary
            } if validation_results else None,
            recommendations=validation_summary.get('recommendations', []) if validation_summary else None
        )
        
        # ä¿å­˜å¤„ç†ç»“æœï¼ˆå¯é€‰ï¼‰
        output_file = CONFIG['output_dir'] / f"{request_id}_result.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(result.dict(), f, indent=2, ensure_ascii=False, default=str)
        
        logger.info(f"æ–‡æ¡£å¤„ç†å®Œæˆ - ID: {request_id}, ç±»å‹: {result.document_type}, æ—¶é—´: {processing_time:.2f}s")
        
        return result
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ–‡æ¡£å¤„ç†å¤±è´¥ - ID: {request_id}, é”™è¯¯: {e}")
        
        return ProcessingResult(
            request_id=request_id,
            status="error",
            processing_time=time.time() - start_time,
            error_message=str(e)
        )

@app.get("/statistics")
async def get_statistics():
    """è·å–å¤„ç†ç»Ÿè®¡ä¿¡æ¯"""
    try:
        output_files = list(CONFIG['output_dir'].glob("*_result.json"))
        
        total_processed = len(output_files)
        document_types = {}
        success_count = 0
        total_processing_time = 0
        
        for file_path in output_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    result = json.load(f)
                
                if result.get('status') == 'success':
                    success_count += 1
                    doc_type = result.get('document_type', 'unknown')
                    document_types[doc_type] = document_types.get(doc_type, 0) + 1
                    total_processing_time += result.get('processing_time', 0)
                    
            except Exception as e:
                logger.warning(f"è¯»å–ç»“æœæ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        
        avg_processing_time = total_processing_time / success_count if success_count > 0 else 0
        
        return {
            "total_processed": total_processed,
            "success_count": success_count,
            "success_rate": success_count / total_processed if total_processed > 0 else 0,
            "document_types": document_types,
            "average_processing_time": avg_processing_time,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ç»Ÿè®¡ä¿¡æ¯è·å–å¤±è´¥: {e}")

@app.post("/batch_process")
async def batch_process(files: List[UploadFile] = File(...)):
    """æ‰¹é‡å¤„ç†æ–‡æ¡£"""
    if len(files) > 10:
        raise HTTPException(status_code=400, detail="æ‰¹é‡å¤„ç†æœ€å¤šæ”¯æŒ10ä¸ªæ–‡ä»¶")
    
    results = []
    
    for file in files:
        try:
            result = await process_document(file)
            results.append(result)
        except Exception as e:
            results.append(ProcessingResult(
                request_id=str(uuid.uuid4()),
                status="error",
                processing_time=0,
                error_message=f"æ–‡ä»¶ {file.filename} å¤„ç†å¤±è´¥: {e}"
            ))
    
    return {"batch_results": results, "total_files": len(files)}

if __name__ == "__main__":
    import uvicorn
    import io
    
    logger.info("å¯åŠ¨åŒ»ç–—ä¿é™©æ–‡æ¡£å¤„ç†æœåŠ¡...")
    uvicorn.run(
        app, 
        host="0.0.0.0", 
        port=8000,
        reload=False,
        log_level="info"
    ) 