#!/usr/bin/env python3
"""
FUNSDæ•°æ®é›†å¤„ç†å™¨
å¤„ç†è¡¨å•ç†è§£æ•°æ®ï¼Œå‡†å¤‡LayoutLMv3è®­ç»ƒ
"""

import os
import sys
import json
import pandas as pd
import numpy as np
from pathlib import Path
from PIL import Image
import logging
from collections import defaultdict
import cv2

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class FUNSDProcessor:
    """FUNSDæ•°æ®é›†å¤„ç†å™¨"""
    
    def __init__(self, data_dir):
        self.data_dir = Path(data_dir)
        self.output_dir = self.data_dir / "processed"
        self.output_dir.mkdir(exist_ok=True)
        
        # FUNSDæ ‡ç­¾æ˜ å°„
        self.label_map = {
            'O': 0,          # Outside
            'B-HEADER': 1,   # Begin Header
            'I-HEADER': 2,   # Inside Header
            'B-QUESTION': 3, # Begin Question
            'I-QUESTION': 4, # Inside Question
            'B-ANSWER': 5,   # Begin Answer
            'I-ANSWER': 6,   # Inside Answer
            'B-OTHER': 7,    # Begin Other
            'I-OTHER': 8     # Inside Other
        }
        
        self.id2label = {v: k for k, v in self.label_map.items()}
        
        # åŒ»ç–—è¡¨å•ç›¸å…³å­—æ®µæ˜ å°„ï¼ˆæ‰©å±•FUNSDç”¨äºåŒ»ç–—åœºæ™¯ï¼‰
        self.medical_fields = {
            'provider_name': ['doctor', 'physician', 'provider', 'clinic', 'hospital'],
            'provider_phone': ['phone', 'tel', 'telephone', 'contact'],
            'provider_npi': ['npi', 'provider id', 'physician id'],
            'patient_id': ['patient id', 'member id', 'subscriber id'],
            'patient_name': ['patient', 'name', 'subscriber', 'member'],
            'charge_total': ['total', 'amount', 'charge', 'cost', 'fee'],
            'diagnosis_code': ['diagnosis', 'dx', 'icd', 'code'],
            'service_date': ['date', 'service date', 'dos', 'treatment date']
        }
    
    def load_funsd_annotation(self, annotation_path):
        """åŠ è½½FUNSDæ ‡æ³¨æ–‡ä»¶"""
        with open(annotation_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        return data
    
    def extract_words_and_boxes(self, annotation_data, image_path):
        """ä»æ ‡æ³¨æ•°æ®ä¸­æå–å•è¯å’Œè¾¹ç•Œæ¡†"""
        words = []
        boxes = []
        labels = []
        
        # è·å–å›¾ç‰‡å°ºå¯¸
        try:
            image = Image.open(image_path)
            img_width, img_height = image.size
        except Exception as e:
            logger.warning(f"æ— æ³•åŠ è½½å›¾ç‰‡ {image_path}: {e}")
            img_width, img_height = 1000, 1000  # é»˜è®¤å°ºå¯¸
        
        for item in annotation_data['form']:
            # è·å–å®ä½“æ ‡ç­¾
            entity_label = item.get('label', 'other').lower()
            
            # æ˜ å°„åˆ°BIOæ ‡è®°
            if 'header' in entity_label:
                bio_prefix = 'HEADER'
            elif 'question' in entity_label:
                bio_prefix = 'QUESTION'  
            elif 'answer' in entity_label:
                bio_prefix = 'ANSWER'
            else:
                bio_prefix = 'OTHER'
            
            # å¤„ç†å•è¯
            first_word = True
            for word_info in item.get('words', []):
                word_text = word_info.get('text', '').strip()
                if not word_text:
                    continue
                
                # BIOæ ‡è®°
                if first_word:
                    label = f'B-{bio_prefix}'
                    first_word = False
                else:
                    label = f'I-{bio_prefix}'
                
                # è¾¹ç•Œæ¡† (ç›¸å¯¹åæ ‡è½¬æ¢)
                bbox = word_info.get('box', [0, 0, 100, 100])
                if len(bbox) == 4:
                    x1, y1, x2, y2 = bbox
                    # ç¡®ä¿åæ ‡åœ¨åˆç†èŒƒå›´å†…
                    x1 = max(0, min(x1, img_width))
                    y1 = max(0, min(y1, img_height))
                    x2 = max(x1, min(x2, img_width))
                    y2 = max(y1, min(y2, img_height))
                    
                    # è½¬æ¢ä¸ºLayoutLMv3æ ¼å¼ (normalized coordinates)
                    norm_box = [
                        int(1000 * x1 / img_width),
                        int(1000 * y1 / img_height),
                        int(1000 * x2 / img_width),
                        int(1000 * y2 / img_height)
                    ]
                else:
                    norm_box = [0, 0, 1000, 1000]
                
                words.append(word_text)
                boxes.append(norm_box)
                labels.append(self.label_map.get(label, 0))
        
        return words, boxes, labels
    
    def create_medical_synthetic_data(self, base_words, base_boxes, base_labels, num_samples=50):
        """åˆ›å»ºåŒ»ç–—è¡¨å•åˆæˆæ•°æ®"""
        synthetic_data = []
        
        # åŒ»ç–—è¡¨å•æ¨¡æ¿
        medical_templates = [
            {
                'provider_name': 'Dr. John Smith',
                'provider_phone': '(555) 123-4567',
                'provider_npi': '1234567890',
                'patient_id': 'P123456',
                'patient_name': 'Jane Doe',
                'charge_total': '$150.00',
                'diagnosis_code': 'M79.3',
                'service_date': '01/15/2024'
            },
            {
                'provider_name': 'City Medical Center',
                'provider_phone': '555-987-6543',
                'provider_npi': '9876543210',
                'patient_id': 'MED789',
                'patient_name': 'Robert Johnson',
                'charge_total': '$275.50',
                'diagnosis_code': 'J06.9',
                'service_date': '02/20/2024'
            }
        ]
        
        import random
        
        for i in range(num_samples):
            template = random.choice(medical_templates)
            
            # éšæœºä¿®æ”¹æ¨¡æ¿å€¼
            sample = {}
            for field, value in template.items():
                if field == 'provider_name':
                    names = ['Dr. Smith', 'Dr. Johnson', 'Dr. Brown', 'Medical Center', 'Clinic']
                    sample[field] = random.choice(names)
                elif field == 'provider_phone':
                    sample[field] = f"({random.randint(200,999)}) {random.randint(100,999)}-{random.randint(1000,9999)}"
                elif field == 'provider_npi':
                    sample[field] = str(random.randint(1000000000, 9999999999))
                elif field == 'patient_id':
                    sample[field] = f"P{random.randint(10000, 99999)}"
                elif field == 'patient_name':
                    first_names = ['John', 'Jane', 'Robert', 'Mary', 'David', 'Sarah']
                    last_names = ['Smith', 'Johnson', 'Brown', 'Davis', 'Wilson', 'Moore']
                    sample[field] = f"{random.choice(first_names)} {random.choice(last_names)}"
                elif field == 'charge_total':
                    amount = random.randint(50, 500)
                    sample[field] = f"${amount}.00"
                elif field == 'diagnosis_code':
                    codes = ['M79.3', 'J06.9', 'K59.0', 'R50.9', 'Z00.00']
                    sample[field] = random.choice(codes)
                elif field == 'service_date':
                    month = random.randint(1, 12)
                    day = random.randint(1, 28)
                    sample[field] = f"{month:02d}/{day:02d}/2024"
                else:
                    sample[field] = value
            
            synthetic_data.append(sample)
        
        return synthetic_data
    
    def process_split(self, split_name):
        """å¤„ç†å•ä¸ªæ•°æ®é›†åˆ†å‰²"""
        logger.info(f"å¤„ç† {split_name} æ•°æ®...")
        
        split_dir = self.data_dir / f"{split_name}_data"
        if not split_dir.exists():
            logger.warning(f"{split_name} ç›®å½•ä¸å­˜åœ¨: {split_dir}")
            return []
        
        annotations_dir = split_dir / "annotations"
        images_dir = split_dir / "images"
        
        processed_data = []
        
        # å¤„ç†æ¯ä¸ªæ ‡æ³¨æ–‡ä»¶
        if annotations_dir.exists():
            for annotation_file in annotations_dir.glob("*.json"):
                try:
                    # åŠ è½½æ ‡æ³¨
                    annotation_data = self.load_funsd_annotation(annotation_file)
                    
                    # å¯¹åº”çš„å›¾ç‰‡æ–‡ä»¶
                    image_file = images_dir / f"{annotation_file.stem}.png"
                    if not image_file.exists():
                        logger.warning(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_file}")
                        continue
                    
                    # æå–å•è¯ã€è¾¹ç•Œæ¡†å’Œæ ‡ç­¾
                    words, boxes, labels = self.extract_words_and_boxes(
                        annotation_data, image_file
                    )
                    
                    if words:
                        processed_data.append({
                            'id': annotation_file.stem,
                            'image_path': str(image_file.relative_to(self.data_dir)),
                            'words': words,
                            'boxes': boxes,
                            'labels': labels
                        })
                        
                except Exception as e:
                    logger.error(f"å¤„ç†æ–‡ä»¶å¤±è´¥ {annotation_file}: {e}")
        
        logger.info(f"{split_name} æ•°æ®å¤„ç†å®Œæˆ: {len(processed_data)} ä¸ªæ ·æœ¬")
        return processed_data
    
    def create_cms_synthetic_data(self, num_samples=100):
        """åˆ›å»ºCMS-1500è¡¨å•åˆæˆæ•°æ®"""
        logger.info("åˆ›å»ºCMS-1500åˆæˆæ•°æ®...")
        
        synthetic_samples = []
        
        # åˆ›å»ºç®€å•çš„åˆæˆCMS-1500è¡¨å•æ•°æ®
        for i in range(num_samples):
            # æ¨¡æ‹ŸCMS-1500è¡¨å•çš„å…³é”®å­—æ®µ
            sample_data = {
                'id': f'cms_synthetic_{i:03d}',
                'image_path': f'synthetic/cms_{i:03d}.png',  # è™šæ‹Ÿè·¯å¾„
                'words': [
                    'HEALTH', 'INSURANCE', 'CLAIM', 'FORM',
                    'Provider:', 'Dr.', 'John', 'Smith',
                    'Phone:', '555-123-4567',
                    'NPI:', '1234567890',
                    'Patient:', 'Jane', 'Doe',
                    'ID:', 'P123456',
                    'Total:', '$250.00',
                    'Date:', '01/15/2024',
                    'Diagnosis:', 'M79.3'
                ],
                'boxes': [
                    [50, 50, 150, 80], [160, 50, 280, 80], [290, 50, 380, 80], [390, 50, 450, 80],  # æ ‡é¢˜
                    [50, 150, 120, 180], [130, 150, 160, 180], [170, 150, 220, 180], [230, 150, 290, 180],  # Provider
                    [50, 200, 110, 230], [120, 200, 250, 230],  # Phone
                    [50, 250, 90, 280], [100, 250, 200, 280],  # NPI
                    [50, 300, 120, 330], [130, 300, 180, 330], [190, 300, 240, 330],  # Patient
                    [50, 350, 80, 380], [90, 350, 150, 380],  # ID
                    [50, 400, 100, 430], [110, 400, 180, 430],  # Total
                    [50, 450, 100, 480], [110, 450, 190, 480],  # Date
                    [50, 500, 130, 530], [140, 500, 200, 530]  # Diagnosis
                ],
                'labels': [
                    7, 7, 7, 7,  # OTHER (title)
                    3, 5, 5, 5,  # QUESTION, ANSWER, ANSWER, ANSWER (provider)
                    3, 5,        # QUESTION, ANSWER (phone)
                    3, 5,        # QUESTION, ANSWER (npi)
                    3, 5, 5,     # QUESTION, ANSWER, ANSWER (patient)
                    3, 5,        # QUESTION, ANSWER (id)
                    3, 5,        # QUESTION, ANSWER (total)
                    3, 5,        # QUESTION, ANSWER (date)
                    3, 5         # QUESTION, ANSWER (diagnosis)
                ]
            }
            
            synthetic_samples.append(sample_data)
        
        logger.info(f"åˆ›å»ºäº† {len(synthetic_samples)} ä¸ªCMS-1500åˆæˆæ ·æœ¬")
        return synthetic_samples
    
    def save_processed_data(self, train_data, val_data, test_data):
        """ä¿å­˜å¤„ç†åçš„æ•°æ®"""
        logger.info("ä¿å­˜å¤„ç†åçš„æ•°æ®...")
        
        # ä¿å­˜ä¸ºJSONæ ¼å¼ï¼ˆLayoutLMv3è®­ç»ƒæ ¼å¼ï¼‰
        datasets = {
            'train': train_data,
            'validation': val_data,
            'test': test_data
        }
        
        for split_name, data in datasets.items():
            output_file = self.output_dir / f"{split_name}.json"
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
            logger.info(f"ä¿å­˜ {split_name}: {len(data)} ä¸ªæ ·æœ¬ -> {output_file}")
        
        # ä¿å­˜æ ‡ç­¾æ˜ å°„
        label_info = {
            'label_map': self.label_map,
            'id2label': self.id2label,
            'num_labels': len(self.label_map),
            'medical_fields': self.medical_fields
        }
        
        with open(self.output_dir / "label_info.json", 'w', encoding='utf-8') as f:
            json.dump(label_info, f, indent=2, ensure_ascii=False)
        
        # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
        stats = {
            'total_train': len(train_data),
            'total_val': len(val_data),
            'total_test': len(test_data),
            'label_distribution': self._calculate_label_distribution(train_data + val_data + test_data)
        }
        
        with open(self.output_dir / "statistics.json", 'w', encoding='utf-8') as f:
            json.dump(stats, f, indent=2, ensure_ascii=False)
        
        logger.info("æ•°æ®ä¿å­˜å®Œæˆ")
    
    def _calculate_label_distribution(self, all_data):
        """è®¡ç®—æ ‡ç­¾åˆ†å¸ƒ"""
        label_counts = defaultdict(int)
        
        for sample in all_data:
            for label in sample['labels']:
                label_name = self.id2label.get(label, 'unknown')
                label_counts[label_name] += 1
        
        return dict(label_counts)
    
    def process(self):
        """ä¸»å¤„ç†æµç¨‹"""
        logger.info("å¼€å§‹å¤„ç†FUNSDæ•°æ®é›†...")
        
        # å¤„ç†åŸå§‹FUNSDæ•°æ®
        train_data = self.process_split('training')
        test_data = self.process_split('testing')
        
        # ä»è®­ç»ƒæ•°æ®ä¸­åˆ’åˆ†éªŒè¯é›†
        import random
        random.seed(42)
        
        if train_data:
            # 80-20åˆ†å‰²
            split_idx = int(0.8 * len(train_data))
            random.shuffle(train_data)
            
            funsd_train = train_data[:split_idx]
            funsd_val = train_data[split_idx:]
        else:
            funsd_train = []
            funsd_val = []
        
        # åˆ›å»ºåŒ»ç–—è¡¨å•åˆæˆæ•°æ®
        cms_synthetic_data = self.create_cms_synthetic_data(num_samples=100)
        
        # åˆå¹¶æ•°æ®
        final_train = funsd_train + cms_synthetic_data[:80]  # å¤§éƒ¨åˆ†åˆæˆæ•°æ®ç”¨äºè®­ç»ƒ
        final_val = funsd_val + cms_synthetic_data[80:]      # å°‘éƒ¨åˆ†ç”¨äºéªŒè¯
        final_test = test_data
        
        # å¦‚æœæ²¡æœ‰æµ‹è¯•æ•°æ®ï¼Œä»éªŒè¯ä¸­åˆ†ä¸€äº›
        if not final_test and final_val:
            split_idx = len(final_val) // 2
            final_test = final_val[split_idx:]
            final_val = final_val[:split_idx]
        
        # ä¿å­˜å¤„ç†åçš„æ•°æ®
        self.save_processed_data(final_train, final_val, final_test)
        
        logger.info("ğŸ‰ FUNSDæ•°æ®å¤„ç†å®Œæˆï¼")
        logger.info(f"è®­ç»ƒé›†: {len(final_train)}")
        logger.info(f"éªŒè¯é›†: {len(final_val)}")
        logger.info(f"æµ‹è¯•é›†: {len(final_test)}")
        
        return True

def main():
    """ä¸»å‡½æ•°"""
    # è·å–æ•°æ®ç›®å½•
    base_dir = Path(__file__).parent.parent
    funsd_dir = base_dir / "data" / "funsd"
    
    if not funsd_dir.exists():
        logger.error(f"FUNSDæ•°æ®ç›®å½•ä¸å­˜åœ¨: {funsd_dir}")
        logger.error("è¯·å…ˆè¿è¡Œ python scripts/download_datasets.py")
        return False
    
    # åˆ›å»ºå¤„ç†å™¨å¹¶å¤„ç†æ•°æ®
    processor = FUNSDProcessor(funsd_dir)
    success = processor.process()
    
    if success:
        logger.info("FUNSDæ•°æ®é¢„å¤„ç†æˆåŠŸå®Œæˆï¼")
        logger.info(f"å¤„ç†åçš„æ•°æ®ä¿å­˜åœ¨: {processor.output_dir}")
    else:
        logger.error("FUNSDæ•°æ®é¢„å¤„ç†å¤±è´¥")
    
    return success

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 