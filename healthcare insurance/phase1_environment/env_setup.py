#!/usr/bin/env python3
"""
ç¯å¢ƒè®¾ç½®è„šæœ¬ - åŒ»ç–—ä¿é™©æ–‡æ¡£å¤„ç†ç³»ç»Ÿ
æ£€æŸ¥GPUã€ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹ã€éªŒè¯ç¯å¢ƒé…ç½®
"""

import os
import sys
import torch
import platform
from pathlib import Path
from transformers import AutoModel, AutoTokenizer, AutoImageProcessor
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def check_system_info():
    """æ£€æŸ¥ç³»ç»Ÿä¿¡æ¯"""
    logger.info("=== ç³»ç»Ÿä¿¡æ¯æ£€æŸ¥ ===")
    logger.info(f"æ“ä½œç³»ç»Ÿ: {platform.system()} {platform.release()}")
    logger.info(f"Pythonç‰ˆæœ¬: {sys.version}")
    logger.info(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
    
    # æ£€æŸ¥CUDA
    if torch.cuda.is_available():
        logger.info(f"CUDAå¯ç”¨: {torch.version.cuda}")
        logger.info(f"GPUæ•°é‡: {torch.cuda.device_count()}")
        for i in range(torch.cuda.device_count()):
            logger.info(f"GPU {i}: {torch.cuda.get_device_name(i)}")
    else:
        logger.warning("CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUè¿è¡Œï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰")
    
    # æ£€æŸ¥MPS (Apple Silicon)
    if torch.backends.mps.is_available():
        logger.info("Apple MPSå¯ç”¨")
    
    return torch.cuda.is_available() or torch.backends.mps.is_available()

def create_directories():
    """åˆ›å»ºé¡¹ç›®ç›®å½•ç»“æ„"""
    logger.info("=== åˆ›å»ºç›®å½•ç»“æ„ ===")
    
    base_dir = Path(__file__).parent.parent
    directories = [
        "data/raw",
        "data/processed", 
        "data/rvl_cdip",
        "data/funsd",
        "data/cms_forms",
        "models/classification",
        "models/extraction", 
        "outputs/results",
        "outputs/visualizations",
        "phase1_environment",
        "phase2_classification",
        "phase3_extraction",
        "phase4_demo",
        "scripts"
    ]
    
    for dir_path in directories:
        full_path = base_dir / dir_path
        full_path.mkdir(parents=True, exist_ok=True)
        logger.info(f"åˆ›å»ºç›®å½•: {full_path}")

def download_base_models():
    """ä¸‹è½½åŸºç¡€é¢„è®­ç»ƒæ¨¡å‹"""
    logger.info("=== ä¸‹è½½åŸºç¡€æ¨¡å‹ ===")
    
    base_dir = Path(__file__).parent.parent
    models_dir = base_dir / "models"
    
    # DiTæ¨¡å‹ (æ–‡æ¡£åˆ†ç±»)
    logger.info("ä¸‹è½½DiTæ¨¡å‹...")
    try:
        dit_model_name = "microsoft/dit-base-finetuned-rvlcdip"
        dit_model = AutoModel.from_pretrained(dit_model_name)
        dit_processor = AutoImageProcessor.from_pretrained(dit_model_name)
        
        # ä¿å­˜åˆ°æœ¬åœ°
        dit_local_path = models_dir / "dit_base"
        dit_model.save_pretrained(dit_local_path)
        dit_processor.save_pretrained(dit_local_path)
        logger.info(f"DiTæ¨¡å‹å·²ä¿å­˜åˆ°: {dit_local_path}")
        
    except Exception as e:
        logger.error(f"ä¸‹è½½DiTæ¨¡å‹å¤±è´¥: {e}")
    
    # LayoutLMv3æ¨¡å‹ (ä¿¡æ¯æŠ½å–)
    logger.info("ä¸‹è½½LayoutLMv3æ¨¡å‹...")
    try:
        layoutlm_model_name = "microsoft/layoutlmv3-base"
        layoutlm_model = AutoModel.from_pretrained(layoutlm_model_name)
        layoutlm_tokenizer = AutoTokenizer.from_pretrained(layoutlm_model_name)
        
        # ä¿å­˜åˆ°æœ¬åœ°
        layoutlm_local_path = models_dir / "layoutlmv3_base"
        layoutlm_model.save_pretrained(layoutlm_local_path)
        layoutlm_tokenizer.save_pretrained(layoutlm_local_path)
        logger.info(f"LayoutLMv3æ¨¡å‹å·²ä¿å­˜åˆ°: {layoutlm_local_path}")
        
    except Exception as e:
        logger.error(f"ä¸‹è½½LayoutLMv3æ¨¡å‹å¤±è´¥: {e}")

def create_config_file():
    """åˆ›å»ºé…ç½®æ–‡ä»¶"""
    logger.info("=== åˆ›å»ºé…ç½®æ–‡ä»¶ ===")
    
    base_dir = Path(__file__).parent.parent
    config_path = base_dir / "config.py"
    
    config_content = '''"""
é¡¹ç›®é…ç½®æ–‡ä»¶
"""
import torch
from pathlib import Path

# åŸºç¡€è·¯å¾„
BASE_DIR = Path(__file__).parent
DATA_DIR = BASE_DIR / "data"
MODELS_DIR = BASE_DIR / "models"
OUTPUTS_DIR = BASE_DIR / "outputs"

# è®¾å¤‡é…ç½®
if torch.cuda.is_available():
    DEVICE = "cuda"
elif torch.backends.mps.is_available():
    DEVICE = "mps"
else:
    DEVICE = "cpu"

# æ¨¡å‹é…ç½®
MODELS_CONFIG = {
    "dit": {
        "model_name": "microsoft/dit-base-finetuned-rvlcdip",
        "local_path": MODELS_DIR / "dit_base",
        "num_classes": 5,  # ç²¾ç®€ä¸º5ç±»
        "image_size": 224
    },
    "layoutlmv3": {
        "model_name": "microsoft/layoutlmv3-base", 
        "local_path": MODELS_DIR / "layoutlmv3_base",
        "max_length": 512
    }
}

# æ•°æ®é›†é…ç½®
DATASETS_CONFIG = {
    "rvl_cdip": {
        "url": "https://www.cs.cmu.edu/~aharley/rvl-cdip/",
        "local_path": DATA_DIR / "rvl_cdip",
        "selected_classes": ["invoice", "letter", "memo", "email", "form"]
    },
    "funsd": {
        "url": "https://guillaumejaume.github.io/FUNSD/",
        "local_path": DATA_DIR / "funsd"
    }
}

# è®­ç»ƒé…ç½®
TRAINING_CONFIG = {
    "classification": {
        "batch_size": 16,
        "learning_rate": 2e-5,
        "epochs": 3,
        "warmup_steps": 500
    },
    "extraction": {
        "batch_size": 8,
        "learning_rate": 1e-5,
        "epochs": 5,
        "warmup_steps": 1000
    }
}

# APIé…ç½®
API_CONFIG = {
    "host": "0.0.0.0",
    "port": 8000,
    "max_file_size": 10 * 1024 * 1024,  # 10MB
    "allowed_extensions": [".pdf", ".jpg", ".jpeg", ".png", ".tiff"]
}

# ç›®æ ‡å­—æ®µé…ç½® (CMS-1500è¡¨å•)
TARGET_FIELDS = {
    "provider_name": "åŒ»ç–—æä¾›è€…å§“å",
    "provider_phone": "åŒ»ç–—æä¾›è€…ç”µè¯", 
    "provider_npi": "NPIå·ç ",
    "patient_id": "æ‚£è€…ID",
    "patient_name": "æ‚£è€…å§“å",
    "charge_total": "æ€»è´¹ç”¨",
    "diagnosis_code": "è¯Šæ–­ä»£ç ",
    "service_date": "æœåŠ¡æ—¥æœŸ"
}
'''
    
    with open(config_path, 'w', encoding='utf-8') as f:
        f.write(config_content)
    
    logger.info(f"é…ç½®æ–‡ä»¶å·²åˆ›å»º: {config_path}")

def verify_installation():
    """éªŒè¯å®‰è£…æ˜¯å¦æˆåŠŸ"""
    logger.info("=== éªŒè¯å®‰è£… ===")
    
    try:
        # æµ‹è¯•transformers
        from transformers import pipeline
        logger.info("âœ“ Transformersæ­£å¸¸")
        
        # æµ‹è¯•torch
        x = torch.randn(2, 3)
        logger.info("âœ“ PyTorchæ­£å¸¸")
        
        # æµ‹è¯•PIL
        from PIL import Image
        logger.info("âœ“ PILæ­£å¸¸")
        
        # æµ‹è¯•datasets
        from datasets import Dataset
        logger.info("âœ“ Datasetsæ­£å¸¸")
        
        logger.info("æ‰€æœ‰æ ¸å¿ƒä¾èµ–éªŒè¯é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        logger.error(f"éªŒè¯å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    logger.info("å¼€å§‹ç¯å¢ƒè®¾ç½®...")
    
    # æ£€æŸ¥ç³»ç»Ÿ
    has_gpu = check_system_info()
    
    # åˆ›å»ºç›®å½•
    create_directories()
    
    # åˆ›å»ºé…ç½®
    create_config_file()
    
    # ä¸‹è½½æ¨¡å‹
    download_base_models()
    
    # éªŒè¯å®‰è£…
    if verify_installation():
        logger.info("ğŸ‰ ç¯å¢ƒè®¾ç½®å®Œæˆï¼")
        if has_gpu:
            logger.info("ç³»ç»Ÿå·²å‡†å¤‡å¥½è¿›è¡ŒGPUåŠ é€Ÿè®­ç»ƒ")
        else:
            logger.info("ç³»ç»Ÿå°†ä½¿ç”¨CPUè¿›è¡Œè®­ç»ƒï¼ˆå»ºè®®ä½¿ç”¨Colab/Kaggleè·å–å…è´¹GPUï¼‰")
    else:
        logger.error("ç¯å¢ƒè®¾ç½®å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
        return False
    
    return True

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 