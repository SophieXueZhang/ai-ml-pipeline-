{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# LLaVA ç¯å¢ƒè®¾ç½®ä¸å¾®è°ƒæµç¨‹ - ç²¾ç®€ç‰ˆ\n",
        "\n",
        "æœ¬notebookåŒ…å«LLaVAæ¨¡å‹ç¯å¢ƒè®¾ç½®å’ŒLoRAå¾®è°ƒçš„æ ¸å¿ƒæ­¥éª¤ã€‚\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. GPUç¯å¢ƒæ£€æŸ¥\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# æ£€æŸ¥GPUçŠ¶æ€\n",
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. å®‰è£…ä¾èµ–åŒ…\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å®‰è£…Kaggleç”¨äºæ•°æ®ä¸‹è½½\n",
        "%pip install kaggle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# é…ç½®Kaggle API\n",
        "import os\n",
        "import json\n",
        "\n",
        "# ä¸Šä¼ kaggle.jsonåˆ°æ ¹ç›®å½•\n",
        "kaggle_config = {\n",
        "    \"username\": \"your_username\",\n",
        "    \"key\": \"your_api_key\"\n",
        "}\n",
        "\n",
        "# åˆ›å»º.kaggleç›®å½•å¹¶ä¿å­˜é…ç½®\n",
        "os.makedirs(os.path.expanduser('~/.kaggle'), exist_ok=True)\n",
        "with open(os.path.expanduser('~/.kaggle/kaggle.json'), 'w') as f:\n",
        "    json.dump(kaggle_config, f)\n",
        "os.chmod(os.path.expanduser('~/.kaggle/kaggle.json'), 0o600)\n",
        "\n",
        "print(\"âœ“ Kaggle APIé…ç½®å®Œæˆ\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. å…‹éš†å¹¶å®‰è£…LLaVA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å…‹éš†LLaVAä»“åº“\n",
        "import os\n",
        "\n",
        "if os.path.exists(\"LLaVA\"):\n",
        "    print(\"âœ“ LLaVAä»“åº“å·²å­˜åœ¨\")\n",
        "else:\n",
        "    print(\"æ­£åœ¨å…‹éš†LLaVAä»“åº“...\")\n",
        "    !git clone https://github.com/haotian-liu/LLaVA.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# è¿›å…¥LLaVAç›®å½•å¹¶å®‰è£…\n",
        "%cd LLaVA\n",
        "\n",
        "try:\n",
        "    import llava\n",
        "    print(\"âœ“ LLaVAå·²å®‰è£…\")\n",
        "except ImportError:\n",
        "    print(\"æ­£åœ¨å®‰è£…LLaVA...\")\n",
        "    %pip install -e .\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. ä¸‹è½½Flickr30kæ•°æ®é›†\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ä¸‹è½½å’Œå‡†å¤‡Flickr30kæ•°æ®é›†\n",
        "import os\n",
        "import glob\n",
        "\n",
        "if os.path.exists('./data/flickr30k/Images/flickr30k_images'):\n",
        "    print(\"âœ“ Flickr30kæ•°æ®é›†å·²å­˜åœ¨\")\n",
        "    print(f\"æ‰¾åˆ° {len(glob.glob('./data/flickr30k/Images/flickr30k_images/*.jpg'))} ä¸ªå›¾ç‰‡æ–‡ä»¶\")\n",
        "else:\n",
        "    print(\"æ­£åœ¨ä¸‹è½½Flickr30kæ•°æ®é›†...\")\n",
        "    !kaggle datasets download -d hsankesara/flickr-image-dataset\n",
        "    \n",
        "    if os.path.exists('flickr-image-dataset.zip'):\n",
        "        print(\"æ­£åœ¨è§£å‹æ•°æ®é›†...\")\n",
        "        !unzip -q flickr-image-dataset.zip -d ./data/\n",
        "        !rm flickr-image-dataset.zip\n",
        "    else:\n",
        "        print(\"è­¦å‘Š: æ•°æ®é›†æ–‡ä»¶æœªæ‰¾åˆ°\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. è½¬æ¢æ•°æ®æ ¼å¼\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å°†Flickr30kæ•°æ®è½¬æ¢ä¸ºLLaVAæ ¼å¼\n",
        "import os\n",
        "import json\n",
        "\n",
        "converted_file = \"./data/flickr30k/train.json\"\n",
        "\n",
        "if os.path.exists(converted_file):\n",
        "    print(\"âœ“ Dataset already converted to LLaVA format.\")\n",
        "    try:\n",
        "        with open(converted_file, 'r') as f:\n",
        "            data = json.load(f)\n",
        "        print(f\"Found {len(data)} data records.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Could not read {converted_file}: {e}\")\n",
        "else:\n",
        "    print(\"Converting Flickr30k dataset to LLaVA format...\")\n",
        "    \n",
        "    # ä½¿ç”¨å®˜æ–¹è½¬æ¢è„šæœ¬\n",
        "    convert_script = \"llava/data/datasets/convert_flickr30k.py\"\n",
        "    if os.path.exists(convert_script):\n",
        "        print(\"Using official LLaVA conversion script...\")\n",
        "        try:\n",
        "            import subprocess\n",
        "            subprocess.run([\"python\", convert_script, \"--root\", \"./data/flickr30k\"], check=True)\n",
        "            print(\"âœ“ Official script executed successfully.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error executing official script: {e}\")\n",
        "    else:\n",
        "        print(\"Official conversion script not found. Please check LLaVA installation.\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 6. LoRA å¾®è°ƒï¼ˆæ ¸å¿ƒï¼Œâ‰ˆ 1â€“2 å¤© GPUï¼‰\n",
        "\n",
        "### å‚æ•°é…ç½®\n",
        "\n",
        "| å­ä»»åŠ¡ | å»ºè®®å‚æ•° | è¯´æ˜ |\n",
        "|-------|---------|------|\n",
        "| æ¨¡å‹ | `llava-hf/llava-1.6-vicuna-7b-hf` | åŸºç¡€é¢„è®­ç»ƒæ¨¡å‹ |\n",
        "| LoRA | rank=16, Î±=32, dropout=0.05 | ä½ç§©é€‚åº”å‚æ•° |\n",
        "| é‡åŒ– | 8-bit or QLoRAï¼ˆèŠ‚çœæ˜¾å­˜ï¼‰ | é‡åŒ–æ–¹å¼ |\n",
        "| è„šæœ¬ | `llava/train/train_mem.py` | å®˜æ–¹è®­ç»ƒè„šæœ¬ |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# LoRA å¾®è°ƒè®­ç»ƒå‘½ä»¤\n",
        "training_command = \"\"\"\n",
        "python llava/train/train_mem.py \\\\\n",
        "    --model-name llava-hf/llava-1.6-vicuna-7b-hf \\\\\n",
        "    --data ./data/flickr30k/train.json \\\\\n",
        "    --val-data ./data/flickr30k/val.json \\\\\n",
        "    --lora-r 16 --lora-alpha 32 --lora-dropout 0.05 \\\\\n",
        "    --output-dir checkpoints/lora_flickr_ep1 \\\\\n",
        "    --num-epochs 1 --batch-size 4 --lr 1e-4 --fp16\n",
        "\"\"\"\n",
        "\n",
        "print(\"LoRA å¾®è°ƒè®­ç»ƒå‘½ä»¤ï¼š\")\n",
        "print(training_command)\n",
        "\n",
        "print(\"\\nå‚æ•°è¯¦è§£ï¼š\")\n",
        "print(\"--model-name: ä½¿ç”¨çš„åŸºç¡€æ¨¡å‹\")\n",
        "print(\"--data: è®­ç»ƒæ•°æ®è·¯å¾„\") \n",
        "print(\"--val-data: éªŒè¯æ•°æ®è·¯å¾„\")\n",
        "print(\"--lora-r: LoRA rankå‚æ•°ï¼Œæ§åˆ¶ä½ç§©çŸ©é˜µçš„ç»´åº¦\")\n",
        "print(\"--lora-alpha: LoRA alphaå‚æ•°ï¼Œç¼©æ”¾å› å­\")\n",
        "print(\"--lora-dropout: LoRA dropoutç‡ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# è®­ç»ƒå‰ç¯å¢ƒæ£€æŸ¥\n",
        "import os\n",
        "import torch\n",
        "\n",
        "print(\"=== è®­ç»ƒç¯å¢ƒæ£€æŸ¥ ===\")\n",
        "\n",
        "# 1. æ£€æŸ¥GPUçŠ¶æ€\n",
        "print(\"\\n1. GPUçŠ¶æ€æ£€æŸ¥ï¼š\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"âœ… GPUå¯ç”¨\")\n",
        "    print(f\"GPUæ•°é‡: {torch.cuda.device_count()}\")\n",
        "    print(f\"å½“å‰GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"æ˜¾å­˜æ€»é‡: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB\")\n",
        "else:\n",
        "    print(\"âŒ GPUä¸å¯ç”¨ï¼Œå»ºè®®åœ¨GPUç¯å¢ƒä¸­è¿è¡Œ\")\n",
        "\n",
        "# 2. æ£€æŸ¥æ•°æ®æ–‡ä»¶\n",
        "print(\"\\n2. æ•°æ®æ–‡ä»¶æ£€æŸ¥ï¼š\")\n",
        "data_files = [\n",
        "    \"./data/flickr30k/train.json\",\n",
        "    \"./data/flickr30k/val.json\"\n",
        "]\n",
        "\n",
        "for file_path in data_files:\n",
        "    if os.path.exists(file_path):\n",
        "        print(f\"âœ… {file_path} å­˜åœ¨\")\n",
        "    else:\n",
        "        print(f\"âŒ {file_path} ä¸å­˜åœ¨ï¼Œè¯·ç¡®ä¿æ•°æ®å·²å‡†å¤‡\")\n",
        "\n",
        "# 3. åˆ›å»ºè¾“å‡ºç›®å½•\n",
        "print(\"\\n3. åˆ›å»ºè¾“å‡ºç›®å½•ï¼š\")\n",
        "output_dir = \"checkpoints/lora_flickr_ep1\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "print(f\"âœ… è¾“å‡ºç›®å½•å·²åˆ›å»º: {output_dir}\")\n",
        "\n",
        "print(\"\\n=== å‡†å¤‡å°±ç»ªï¼Œå¯ä»¥å¼€å§‹è®­ç»ƒ ===\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 7. åŸºçº¿è¯„ä¼°\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ç”Ÿæˆé¢„æµ‹ä¸è®¡ç®—æŒ‡æ ‡\n",
        "print(\"ğŸ“Š è¯„ä¼°æ­¥éª¤ï¼š\")\n",
        "\n",
        "# 1. ç”Ÿæˆé¢„æµ‹\n",
        "eval_command = \"\"\"\n",
        "python llava/eval/cli_eval.py \\\\\n",
        "    --ckpt checkpoints/lora_flickr_ep1 \\\\\n",
        "    --val-data ./data/flickr30k/val.json \\\\\n",
        "    --outfile pred.json\n",
        "\"\"\"\n",
        "print(\"1. ç”Ÿæˆé¢„æµ‹:\")\n",
        "print(eval_command)\n",
        "\n",
        "# 2. è®¡ç®—æŒ‡æ ‡\n",
        "metrics_command = \"\"\"\n",
        "python scripts/eval_caption.py \\\\\n",
        "    --pred-file pred.json \\\\\n",
        "    --gt-file ./data/flickr30k/val.json\n",
        "\"\"\"\n",
        "print(\"\\n2. è®¡ç®—æŒ‡æ ‡:\")\n",
        "print(metrics_command)\n",
        "\n",
        "print(\"\\nğŸ“‹ è®°å½•å¯¹æ¯”: åŸæ¨¡å‹ vs LoRAå¾®è°ƒåæå‡å€¼\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### å¯è§†åŒ–æ¼”ç¤º\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ç”Ÿæˆæ¼”ç¤ºç´ æï¼ˆ5å¼ å›¾ç‰‡ + æ¨¡å‹è¾“å‡ºå¯¹æ¯”ï¼‰\n",
        "import os, glob, random\n",
        "\n",
        "# åˆ›å»ºæ¼”ç¤ºç›®å½•å’Œé€‰æ‹©å›¾ç‰‡\n",
        "os.makedirs(\"./assets\", exist_ok=True)\n",
        "image_files = glob.glob('./data/flickr30k/Images/flickr30k_images/*.jpg')\n",
        "\n",
        "if len(image_files) >= 5:\n",
        "    demo_images = random.sample(image_files, 5)\n",
        "    \n",
        "    # åˆ›å»ºæ¼”ç¤ºæ–‡æ¡£æ¨¡æ¿\n",
        "    with open(\"./assets/week1_demo.md\", 'w') as f:\n",
        "        f.write(\"# LLaVA LoRA å¾®è°ƒæ¼”ç¤º\\n\\n\")\n",
        "        for i, img_path in enumerate(demo_images, 1):\n",
        "            img_name = os.path.basename(img_path)\n",
        "            f.write(f\"### ç¤ºä¾‹ {i}: {img_name}\\n\")\n",
        "            f.write(\"**åŸæ¨¡å‹**: [å¾…å¡«å…¥]\\n\")\n",
        "            f.write(\"**LoRAå¾®è°ƒ**: [å¾…å¡«å…¥]\\n\\n\")\n",
        "    \n",
        "    print(\"âœ… æ¼”ç¤ºæ–‡æ¡£å·²åˆ›å»º: ./assets/week1_demo.md\")\n",
        "    print(f\"âœ… é€‰ä¸­æ¼”ç¤ºå›¾ç‰‡: {[os.path.basename(p) for p in demo_images]}\")\n",
        "    print(\"ğŸ“‹ åç»­: ç”¨è®­ç»ƒåæ¨¡å‹ç”Ÿæˆæè¿°ï¼Œå¡«å…¥å¯¹æ¯”ç»“æœ\")\n",
        "else:\n",
        "    print(\"âŒ å›¾ç‰‡ä¸è¶³ï¼Œè¯·æ£€æŸ¥æ•°æ®é›†\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "---\n",
        "\n",
        "## ğŸ“ å®Œæ•´æµç¨‹æ€»ç»“\n",
        "\n",
        "**ç¯å¢ƒè®¾ç½®** â†’ **æ•°æ®å‡†å¤‡** â†’ **LoRAå¾®è°ƒ** â†’ **åŸºçº¿è¯„ä¼°**\n",
        "\n",
        "### å…³é”®è¾“å‡ºæ–‡ä»¶ï¼š\n",
        "- `checkpoints/lora_flickr_ep1/` - è®­ç»ƒæ£€æŸ¥ç‚¹\n",
        "- `pred.json` - é¢„æµ‹ç»“æœ  \n",
        "- `assets/week1_demo.md` - æ¼”ç¤ºæ–‡æ¡£\n",
        "\n",
        "### é‡è¦æ³¨æ„äº‹é¡¹ï¼š\n",
        "âš ï¸ **ç¡¬ä»¶**: æ¨è8GB+æ˜¾å­˜GPUï¼Œå¯è°ƒæ•´batch_size  \n",
        "âš ï¸ **æ—¶é—´**: å•GPUè®­ç»ƒçº¦1-2å¤©  \n",
        "âš ï¸ **ç›‘æ§**: å»ºè®®ä½¿ç”¨tensorboardç›‘æ§è®­ç»ƒè¿›åº¦\n",
        "\n",
        "---\n",
        "**ğŸ‰ LLaVA LoRAå¾®è°ƒå®Œæ•´æµç¨‹ï¼** ç´ æå¯ç›´æ¥ç”¨äºHugging Face Spaceã€‚\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
